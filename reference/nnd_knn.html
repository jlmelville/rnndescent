<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="Find Nearest Neighbors and Distances"><title>Find Nearest Neighbors and Distances — nnd_knn • rnndescent</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Find Nearest Neighbors and Distances — nnd_knn"><meta property="og:description" content="Find Nearest Neighbors and Distances"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">rnndescent</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.10</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item">
  <a class="nav-link" href="../articles/rnndescent.html">Get started</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"></ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Find Nearest Neighbors and Distances</h1>
      
      <div class="d-none name"><code>nnd_knn.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Find Nearest Neighbors and Distances</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">nnd_knn</span><span class="op">(</span></span>
<span>  <span class="va">data</span>,</span>
<span>  k <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  metric <span class="op">=</span> <span class="st">"euclidean"</span>,</span>
<span>  init <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  n_iters <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  max_candidates <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  delta <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  low_memory <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  use_alt_metric <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  n_threads <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  progress <span class="op">=</span> <span class="st">"bar"</span>,</span>
<span>  obs <span class="op">=</span> <span class="st">"R"</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>data</dt>
<dd><p>Matrix of <code>n</code> items to generate neighbors for, with observations
in the rows and features in the columns. Optionally, input can be passed
with observations in the columns, by setting <code>obs = "C"</code>, which should be
more efficient.</p></dd>


<dt>k</dt>
<dd><p>Number of nearest neighbors to return. Optional if <code>init</code> is
specified.</p></dd>


<dt>metric</dt>
<dd><p>Type of distance calculation to use. One of:</p><ul><li><p><code>"euclidean"</code>.</p></li>
<li><p><code>"l2sqr"</code> (squared Euclidean).</p></li>
<li><p><code>"cosine"</code>.</p></li>
<li><p><code>"cosine-preprocess"</code>: cosine with preprocessing: this trades memory for a
potential speed up during the distance calculation.It should give the
same results as <code>cosine</code>, give or take minor numerical changes. Be aware
that the distance between two identical items may not always give exactly
zero with this method.</p></li>
<li><p><code>"manhattan"</code>.</p></li>
<li><p><code>"correlation"</code> (1 minus the Pearson correlation).</p></li>
<li><p><code>"correlation-preprocess"</code>: <code>correlation</code> with preprocessing. This trades
memory for a potential speed up during the distance calculation. It should
give the same results as <code>correlation</code>, give or take minor numerical
changes. Be aware that the distance between two identical items may not
always give exactly zero with this method.</p></li>
<li><p><code>"hamming"</code>.</p></li>
<li><p><code>"bhamming"</code> (hamming on binary data with bitset internal memory
optimization).</p></li>
</ul></dd>


<dt>init</dt>
<dd><p>Initial <code>data</code> neighbor graph to optimize. If not provided, <code>k</code>
random neighbors are created. If provided, the input format should be a
list containing:</p><ul><li><p><code>idx</code> an <code>n</code> by <code>k</code> matrix containing the nearest neighbor indices.</p></li>
<li><p><code>dist</code> (optional) an <code>n</code> by <code>k</code> matrix containing the nearest neighbor
distances.</p></li>
</ul><p>If <code>k</code> and <code>init</code> are specified as arguments to this function, and the
number of neighbors provided in <code>init</code> is not equal to <code>k</code> then:</p><ul><li><p>if <code>k</code> is smaller, only the <code>k</code> closest values in <code>init</code> are retained.</p></li>
<li><p>if <code>k</code> is larger, then random neighbors will be chosen to fill <code>init</code> to
the size of <code>k</code>. Note that there is no checking if any of the random
neighbors are duplicates of what is already in <code>init</code> so effectively fewer
than <code>k</code> neighbors may be chosen for some observations under these
circumstances.</p></li>
</ul><p>If the input distances are omitted, they will be calculated for you.</p></dd>


<dt>n_iters</dt>
<dd><p>Number of iterations of nearest neighbor descent to carry out.</p></dd>


<dt>max_candidates</dt>
<dd><p>Maximum number of candidate neighbors to try for each
item in each iteration. Use relative to <code>k</code> to emulate the "rho"
sampling parameter in the nearest neighbor descent paper. By default, this
is set to <code>k</code> or <code>60</code>, whichever is smaller.</p></dd>


<dt>delta</dt>
<dd><p>The minimum relative change in the neighbor graph allowed before
early stopping. Should be a value between 0 and 1. The smaller the value,
the smaller the amount of progress between iterations is allowed. Default
value of <code>0.001</code> means that at least 0.1% of the neighbor graph must
be updated at each iteration.</p></dd>


<dt>low_memory</dt>
<dd><p>If <code>TRUE</code>, use a lower memory, but more
computationally expensive approach to index construction. If set to
<code>FALSE</code>, you should see a noticeable speed improvement, especially
when using a smaller number of threads, so this is worth trying if you have
the memory to spare.</p></dd>


<dt>use_alt_metric</dt>
<dd><p>If <code>TRUE</code>, use faster metrics that maintain the
ordering of distances internally (e.g. squared Euclidean distances if using
<code>metric = "euclidean"</code>), then apply a correction at the end. Probably
the only reason to set this to <code>FALSE</code> is if you suspect that some
sort of numeric issue is occurring with your data in the alternative code
path.</p></dd>


<dt>n_threads</dt>
<dd><p>Number of threads to use.</p></dd>


<dt>verbose</dt>
<dd><p>If <code>TRUE</code>, log information to the console.</p></dd>


<dt>progress</dt>
<dd><p>Determines the type of progress information logged if
<code>verbose = TRUE</code>. Options are:</p><ul><li><p><code>"bar"</code>: a simple text progress bar.</p></li>
<li><p><code>"dist"</code>: the sum of the distances in the approximate knn graph at the
end of each iteration.</p></li>
</ul></dd>


<dt>obs</dt>
<dd><p>set to <code>"C"</code> to indicate that the input <code>data</code> orientation stores
each observation as a column. The default <code>"R"</code> means that observations are
stored in each row. Storing the data by row is usually more convenient, but
internally your data will be converted to column storage. Passing it
already column-oriented will save some memory and (a small amount of) CPU
usage.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>the approximate nearest neighbor graph as a list containing:</p><ul><li><p><code>idx</code> an n by k matrix containing the nearest neighbor indices.</p></li>
<li><p><code>dist</code> an n by k matrix containing the nearest neighbor distances.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Dong, W., Moses, C., &amp; Li, K. (2011, March).
Efficient k-nearest neighbor graph construction for generic similarity measures.
In <em>Proceedings of the 20th international conference on World Wide Web</em>
(pp. 577-586).
ACM.
<a href="https://doi.org/10.1145/1963405.1963487" class="external-link">https://doi.org/10.1145/1963405.1963487</a>.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># Find 4 (approximate) nearest neighbors using Euclidean distance</span></span></span>
<span class="r-in"><span><span class="co"># If you pass a data frame, non-numeric columns are removed</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Manhattan (l1) distance</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"manhattan"</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Multi-threading: you can choose the number of threads to use: in real</span></span></span>
<span class="r-in"><span><span class="co"># usage, you will want to set n_threads to at least 2</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"manhattan"</span>, n_threads <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Use verbose flag to see information about progress</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 22:28:54 Initializing from random neighbors</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 22:28:54 Generating random k-nearest neighbor graph with k = 4</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 22:28:54 Finished</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 22:28:54 Running nearest neighbor descent for 10 iterations</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 22:28:54 Finished</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Nearest neighbor descent uses random initialization, but you can pass any</span></span></span>
<span class="r-in"><span><span class="co"># approximation using the init argument (as long as the metrics used to</span></span></span>
<span class="r-in"><span><span class="co"># calculate the initialization are compatible with the metric options used</span></span></span>
<span class="r-in"><span><span class="co"># by nnd_knn).</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu"><a href="random_knn.html">random_knn</a></span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, init <span class="op">=</span> <span class="va">iris_nn</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 22:28:54 Running nearest neighbor descent for 10 iterations</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 22:28:54 Finished</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Number of iterations controls how much optimization is attempted. A smaller</span></span></span>
<span class="r-in"><span><span class="co"># value will run faster but give poorer results</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span>, n_iters <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># You can also control the amount of work done within an iteration by</span></span></span>
<span class="r-in"><span><span class="co"># setting max_candidates</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span>, max_candidates <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Optimization may also stop early if not much progress is being made. This</span></span></span>
<span class="r-in"><span><span class="co"># convergence criterion can be controlled via delta. A larger value will</span></span></span>
<span class="r-in"><span><span class="co"># stop progress earlier. The verbose flag will provide some information if</span></span></span>
<span class="r-in"><span><span class="co"># convergence is occurring before all iterations are carried out.</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span>, n_iters <span class="op">=</span> <span class="fl">5</span>, delta <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># To ensure that descent only stops if no improvements are made, set delta = 0</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span>, n_iters <span class="op">=</span> <span class="fl">5</span>, delta <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># A faster version of the algorithm is available that avoids repeated</span></span></span>
<span class="r-in"><span><span class="co"># distance calculations at the cost of using more RAM. Set low_memory to</span></span></span>
<span class="r-in"><span><span class="co"># FALSE to try it.</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">nnd_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span>, low_memory <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by James Melville.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

