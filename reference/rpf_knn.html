<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content='Find approximate nearest neighbors using a "forest" of Random Projection
Trees (Dasgupta and Freund, 2008).'><title>Find Nearest Neighbors and Distances Using A Random Projection Forest — rpf_knn • rnndescent</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Find Nearest Neighbors and Distances Using A Random Projection Forest — rpf_knn"><meta property="og:description" content='Find approximate nearest neighbors using a "forest" of Random Projection
Trees (Dasgupta and Freund, 2008).'><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">rnndescent</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.15</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/hubness.html">Hubness</a>
    <a class="dropdown-item" href="../articles/nearest-neighbor-descent.html">Nearest Neighbor Descent</a>
    <a class="dropdown-item" href="../articles/querying-data.html">Querying Data</a>
    <a class="dropdown-item" href="../articles/random-partition-forests.html">Random Partition Forests</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"></ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Find Nearest Neighbors and Distances Using A Random Projection Forest</h1>
      
      <div class="d-none name"><code>rpf_knn.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Find approximate nearest neighbors using a "forest" of Random Projection
Trees (Dasgupta and Freund, 2008).</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">rpf_knn</span><span class="op">(</span></span>
<span>  <span class="va">data</span>,</span>
<span>  <span class="va">k</span>,</span>
<span>  metric <span class="op">=</span> <span class="st">"euclidean"</span>,</span>
<span>  use_alt_metric <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  n_trees <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  leaf_size <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  max_tree_depth <span class="op">=</span> <span class="fl">200</span>,</span>
<span>  include_self <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  ret_forest <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  margin <span class="op">=</span> <span class="st">"auto"</span>,</span>
<span>  n_threads <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  obs <span class="op">=</span> <span class="st">"R"</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>data</dt>
<dd><p>Matrix of <code>n</code> items to generate neighbors for, with observations
in the rows and features in the columns. Optionally, input can be passed
with observations in the columns, by setting <code>obs = "C"</code>, which should be
more efficient. Possible formats are <code><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">base::data.frame()</a></code>, <code><a href="https://rdrr.io/r/base/matrix.html" class="external-link">base::matrix()</a></code>
or <code><a href="https://rdrr.io/pkg/Matrix/man/sparseMatrix.html" class="external-link">Matrix::sparseMatrix()</a></code>. Sparse matrices should be in <code>dgCMatrix</code>
format. Dataframes will be converted to <code>numerical</code> matrix format
internally, so if your data columns are <code>logical</code> and intended to be used
with the specialized binary <code>metric</code>s, you should convert it to a logical
matrix first (otherwise you will get the slower dense numerical version).</p></dd>


<dt>k</dt>
<dd><p>Number of nearest neighbors to return. Optional if <code>init</code> is
specified.</p></dd>


<dt>metric</dt>
<dd><p>Type of distance calculation to use. One of:</p><ul><li><p><code>"braycurtis"</code></p></li>
<li><p><code>"canberra"</code></p></li>
<li><p><code>"chebyshev"</code></p></li>
<li><p><code>"correlation"</code> (1 minus the Pearson correlation)</p></li>
<li><p><code>"cosine"</code></p></li>
<li><p><code>"dice"</code></p></li>
<li><p><code>"euclidean"</code></p></li>
<li><p><code>"hamming"</code></p></li>
<li><p><code>"hellinger"</code></p></li>
<li><p><code>"jaccard"</code></p></li>
<li><p><code>"jensenshannon"</code></p></li>
<li><p><code>"kulsinski"</code></p></li>
<li><p><code>"sqeuclidean"</code> (squared Euclidean)</p></li>
<li><p><code>"manhattan"</code></p></li>
<li><p><code>"rogerstanimoto"</code></p></li>
<li><p><code>"russellrao"</code></p></li>
<li><p><code>"sokalmichener"</code></p></li>
<li><p><code>"sokalsneath"</code></p></li>
<li><p><code>"spearmanr"</code> (1 minus the Spearman rank correlation)</p></li>
<li><p><code>"symmetrickl"</code> (symmetric Kullback-Leibler divergence)</p></li>
<li><p><code>"tsss"</code> (Triangle Area Similarity-Sector Area Similarity or TS-SS
metric)</p></li>
<li><p><code>"yule"</code></p></li>
</ul><p>For non-sparse data, the following variants are available with
preprocessing: this trades memory for a potential speed up during the
distance calculation. Some minor numerical differences should be expected
compared to the non-preprocessed versions:</p><ul><li><p><code>"cosine-preprocess"</code>: <code>cosine</code> with preprocessing.</p></li>
<li><p><code>"correlation-preprocess"</code>: <code>correlation</code> with preprocessing.</p></li>
</ul><p>For non-sparse binary data passed as a <code>logical</code> matrix, the following
metrics have specialized variants which should be substantially faster than
the non-binary variants (in other cases the logical data will be treated as
a dense numeric vector of 0s and 1s):</p><ul><li><p><code>"dice"</code></p></li>
<li><p><code>"hamming"</code></p></li>
<li><p><code>"jaccard"</code></p></li>
<li><p><code>"kulsinski"</code></p></li>
<li><p><code>"matching"</code></p></li>
<li><p><code>"rogerstanimoto"</code></p></li>
<li><p><code>"russellrao"</code></p></li>
<li><p><code>"sokalmichener"</code></p></li>
<li><p><code>"sokalsneath"</code></p></li>
<li><p><code>"yule"</code></p></li>
</ul><p>Note that if <code>margin = "explicit"</code>, the metric is only used to determine
whether an "angular" or "Euclidean" distance is used to measure the
distance between split points in the tree.</p></dd>


<dt>use_alt_metric</dt>
<dd><p>If <code>TRUE</code>, use faster metrics that maintain the
ordering of distances internally (e.g. squared Euclidean distances if using
<code>metric = "euclidean"</code>), then apply a correction at the end. Probably
the only reason to set this to <code>FALSE</code> is if you suspect that some
sort of numeric issue is occurring with your data in the alternative code
path.</p></dd>


<dt>n_trees</dt>
<dd><p>The number of trees to use in the RP forest. A larger number
will give more accurate results at the cost of a longer computation time.
The default of <code>NULL</code> means that the number is chosen based on the number
of observations in <code>data</code>.</p></dd>


<dt>leaf_size</dt>
<dd><p>The maximum number of items that can appear in a leaf. The
default of <code>NULL</code> means that the number of leaves is chosen based on the
number of requested neighbors <code>k</code>.</p></dd>


<dt>max_tree_depth</dt>
<dd><p>The maximum depth of the tree to build (default = 200).
If the maximum tree depth is exceeded then the leaf size of a tree may
exceed <code>leaf_size</code> which can result in a large number of neighbor distances
being calculated. If <code>verbose = TRUE</code> a message will be logged to indicate
that the leaf size is large. However, increasing the <code>max_tree_depth</code> may
not help: it may be that there is something unusual about the distribution
of your data set under your chose <code>metric</code> that makes a tree-based
initialization inappropriate.</p></dd>


<dt>include_self</dt>
<dd><p>If <code>TRUE</code> (the default) then an item is considered to
be a neighbor of itself. Hence the first nearest neighbor in the results
will be the item itself. This is a convention that many nearest neighbor
methods and software adopt, so if you want to use the resulting knn graph
from this function in downstream applications or compare with other
methods, you should probably keep this set to <code>TRUE</code>. However, if you are
planning on using the result of this as initialization to another nearest
neighbor method (e.g. <code><a href="nnd_knn.html">nnd_knn()</a></code>), then set this to <code>FALSE</code>.</p></dd>


<dt>ret_forest</dt>
<dd><p>If <code>TRUE</code> also return a search forest which can be used
for future querying (via <code><a href="rpf_knn_query.html">rpf_knn_query()</a></code>) and filtering
(via <code><a href="rpf_filter.html">rpf_filter()</a></code>). By default this is <code>FALSE</code>. Setting this to <code>TRUE</code>
will change the output list to be nested (see the <code>Value</code> section below).</p></dd>


<dt>margin</dt>
<dd><p>A character string specifying the method used to  assign points
to one side of the hyperplane or the other. Possible values are:</p><ul><li><p><code>"explicit"</code> categorizes all distance metrics as either Euclidean or
Angular (Euclidean after normalization), explicitly calculates a hyperplane
and offset, and then calculates the margin based on the dot product with
the hyperplane.</p></li>
<li><p><code>"implicit"</code> calculates the distance from a point to each of the
points defining the normal vector. The margin is calculated by comparing the
two distances: the point is assigned to the side of the hyperplane that
the normal vector point with the closest distance belongs to.</p></li>
<li><p><code>"auto"</code> (the default) picks the margin method depending on whether a
binary-specific <code>metric</code> such as <code>"bhammming"</code> is chosen, in which case
<code>"implicit"</code> is used, and <code>"explicit"</code> otherwise: binary-specific metrics
involve storing the data in a way that isn't very efficient for the
<code>"explicit"</code> method and the binary-specific metric is usually a lot faster
than the generic equivalent such that the cost of two distance calculations
for the margin method is still faster.</p></li>
</ul></dd>


<dt>n_threads</dt>
<dd><p>Number of threads to use.</p></dd>


<dt>verbose</dt>
<dd><p>If <code>TRUE</code>, log information to the console.</p></dd>


<dt>obs</dt>
<dd><p>set to <code>"C"</code> to indicate that the input <code>data</code> orientation stores
each observation as a column. The default <code>"R"</code> means that observations are
stored in each row. Storing the data by row is usually more convenient, but
internally your data will be converted to column storage. Passing it
already column-oriented will save some memory and (a small amount of) CPU
usage.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>the approximate nearest neighbor graph as a list containing:</p><ul><li><p><code>idx</code> an n by k matrix containing the nearest neighbor indices.</p></li>
<li><p><code>dist</code> an n by k matrix containing the nearest neighbor distances.</p></li>
<li><p><code>forest</code> (if <code>ret_forest = TRUE</code>) the RP forest that generated the
neighbor graph, which can be used to query new data.</p></li>
</ul><p><code>k</code> neighbors per observation are not guaranteed to be found. Missing data
is represented with an index of <code>0</code> and a distance of <code>NA</code>.</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Dasgupta, S., &amp; Freund, Y. (2008, May).
Random projection trees and low dimensional manifolds.
In <em>Proceedings of the fortieth annual ACM symposium on Theory of computing</em>
(pp. 537-546).
<a href="https://doi.org/10.1145/1374376.1374452" class="external-link">https://doi.org/10.1145/1374376.1374452</a>.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p>rpf_filter, nnd_knn</p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># Find 4 (approximate) nearest neighbors using Euclidean distance</span></span></span>
<span class="r-in"><span><span class="co"># If you pass a data frame, non-numeric columns are removed</span></span></span>
<span class="r-in"><span><span class="va">iris_nn</span> <span class="op">&lt;-</span> <span class="fu">rpf_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span>, leaf_size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># If you want to initialize another method (e.g. nearest neighbor descent)</span></span></span>
<span class="r-in"><span><span class="co"># with the result of the RP forest, then it's more efficient to skip</span></span></span>
<span class="r-in"><span><span class="co"># evaluating whether an item is a neighbor of itself by setting</span></span></span>
<span class="r-in"><span><span class="co"># `include_self = FALSE`:</span></span></span>
<span class="r-in"><span><span class="va">iris_rp</span> <span class="op">&lt;-</span> <span class="fu">rpf_knn</span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, n_trees <span class="op">=</span> <span class="fl">3</span>, include_self <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># Use it with e.g. `nnd_knn` -- this should be better than a random start</span></span></span>
<span class="r-in"><span><span class="va">iris_nnd</span> <span class="op">&lt;-</span> <span class="fu"><a href="nnd_knn.html">nnd_knn</a></span><span class="op">(</span><span class="va">iris</span>, k <span class="op">=</span> <span class="fl">4</span>, init <span class="op">=</span> <span class="va">iris_rp</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># but note you can also run nnd_knn(iris, k = 4, init = "tree") to initialize</span></span></span>
<span class="r-in"><span><span class="co"># from an RP forest directly</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># for future querying you may want to also return the RP forest:</span></span></span>
<span class="r-in"><span><span class="va">iris_rpf</span> <span class="op">&lt;-</span> <span class="fu">rpf_knn</span><span class="op">(</span><span class="va">iris</span>,</span></span>
<span class="r-in"><span>  k <span class="op">=</span> <span class="fl">4</span>, n_trees <span class="op">=</span> <span class="fl">3</span>, include_self <span class="op">=</span> <span class="cn">FALSE</span>,</span></span>
<span class="r-in"><span>  ret_forest <span class="op">=</span> <span class="cn">TRUE</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># forest and nn data can be used to create a smaller forest for querying</span></span></span>
<span class="r-in"><span><span class="co"># filtered_forest &lt;- rpf_filter(iris_rpf)</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by James Melville.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

