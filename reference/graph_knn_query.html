<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="Find Nearest Neighbors and Distances"><title>Find Nearest Neighbors and Distances — graph_knn_query • rnndescent</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Find Nearest Neighbors and Distances — graph_knn_query"><meta property="og:description" content="Find Nearest Neighbors and Distances"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">rnndescent</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.15</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/hubness.html">Hubness</a>
    <a class="dropdown-item" href="../articles/random-partition-forests.html">Random Partition Forests</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"></ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Find Nearest Neighbors and Distances</h1>
      
      <div class="d-none name"><code>graph_knn_query.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Find Nearest Neighbors and Distances</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">graph_knn_query</span><span class="op">(</span></span>
<span>  <span class="va">query</span>,</span>
<span>  <span class="va">reference</span>,</span>
<span>  <span class="va">reference_graph</span>,</span>
<span>  k <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  metric <span class="op">=</span> <span class="st">"euclidean"</span>,</span>
<span>  init <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  epsilon <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  use_alt_metric <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  n_threads <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  obs <span class="op">=</span> <span class="st">"R"</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>query</dt>
<dd><p>Matrix of <code>n</code> query items, with observations in the rows and
features in the columns. Optionally, the data may be passed with the
observations in the columns, by setting <code>obs = "C"</code>, which should be more
efficient. The <code>reference</code> data must be passed in the same orientation as
<code>query</code>. Possible formats are <code><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">base::data.frame()</a></code>, <code><a href="https://rdrr.io/r/base/matrix.html" class="external-link">base::matrix()</a></code>
or <code><a href="https://rdrr.io/pkg/Matrix/man/sparseMatrix.html" class="external-link">Matrix::sparseMatrix()</a></code>. Sparse matrices should be in <code>dgCMatrix</code>
format. Dataframes will be converted to <code>numerical</code> matrix format
internally, so if your data columns are <code>logical</code> and intended to be used
with the specialized binary <code>metric</code>s, you should convert it to a logical
matrix first (otherwise you will get the slower dense numerical version).</p></dd>


<dt>reference</dt>
<dd><p>Matrix of <code>m</code> reference items, with observations in the rows
and features in the columns. The nearest neighbors to the queries are
calculated from this data. Optionally, the data may be passed with the
observations in the columns, by setting <code>obs = "C"</code>, which should be more
efficient. The <code>query</code> data must be passed in the same format and
orientation as <code>reference</code>. Possible formats are <code><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">base::data.frame()</a></code>,
<code><a href="https://rdrr.io/r/base/matrix.html" class="external-link">base::matrix()</a></code> or <code><a href="https://rdrr.io/pkg/Matrix/man/sparseMatrix.html" class="external-link">Matrix::sparseMatrix()</a></code>. Sparse matrices should be in
<code>dgCMatrix</code> format.</p></dd>


<dt>reference_graph</dt>
<dd><p>Search graph of the <code>reference</code> data. A neighbor
graph, such as that output from <code><a href="nnd_knn.html">nnd_knn()</a></code> can be used, but
preferably a suitably prepared sparse search graph should be used, such as
that output by <code><a href="prepare_search_graph.html">prepare_search_graph()</a></code>.</p></dd>


<dt>k</dt>
<dd><p>Number of nearest neighbors to return. Optional if <code>init</code> is
specified.</p></dd>


<dt>metric</dt>
<dd><p>Type of distance calculation to use. One of:</p><ul><li><p><code>"braycurtis"</code></p></li>
<li><p><code>"canberra"</code></p></li>
<li><p><code>"chebyshev"</code></p></li>
<li><p><code>"correlation"</code> (1 minus the Pearson correlation)</p></li>
<li><p><code>"cosine"</code></p></li>
<li><p><code>"dice"</code></p></li>
<li><p><code>"euclidean"</code></p></li>
<li><p><code>"hamming"</code></p></li>
<li><p><code>"hellinger"</code></p></li>
<li><p><code>"jaccard"</code></p></li>
<li><p><code>"jensenshannon"</code></p></li>
<li><p><code>"kulsinski"</code></p></li>
<li><p><code>"sqeuclidean"</code> (squared Euclidean)</p></li>
<li><p><code>"manhattan"</code></p></li>
<li><p><code>"rogerstanimoto"</code></p></li>
<li><p><code>"russellrao"</code></p></li>
<li><p><code>"sokalmichener"</code></p></li>
<li><p><code>"sokalsneath"</code></p></li>
<li><p><code>"spearmanr"</code> (1 minus the Spearman rank correlation)</p></li>
<li><p><code>"symmetrickl"</code> (symmetric Kullback-Leibler divergence)</p></li>
<li><p><code>"tsss"</code> (Triangle Area Similarity-Sector Area Similarity or TS-SS
metric)</p></li>
<li><p><code>"yule"</code></p></li>
</ul><p>For non-sparse data, the following variants are available with
preprocessing: this trades memory for a potential speed up during the
distance calculation. Some minor numerical differences should be expected
compared to the non-preprocessed versions:</p><ul><li><p><code>"cosine-preprocess"</code>: <code>cosine</code> with preprocessing.</p></li>
<li><p><code>"correlation-preprocess"</code>: <code>correlation</code> with preprocessing.</p></li>
</ul><p>For non-sparse binary data passed as a <code>logical</code> matrix, the following
metrics have specialized variants which should be substantially faster than
the non-binary variants (in other cases the logical data will be treated as
a dense numeric vector of 0s and 1s):</p><ul><li><p><code>"dice"</code></p></li>
<li><p><code>"hamming"</code></p></li>
<li><p><code>"jaccard"</code></p></li>
<li><p><code>"kulsinski"</code></p></li>
<li><p><code>"matching"</code></p></li>
<li><p><code>"rogerstanimoto"</code></p></li>
<li><p><code>"russellrao"</code></p></li>
<li><p><code>"sokalmichener"</code></p></li>
<li><p><code>"sokalsneath"</code></p></li>
<li><p><code>"yule"</code></p></li>
</ul></dd>


<dt>init</dt>
<dd><p>Initial <code>query</code> neighbor graph to optimize. If not provided, <code>k</code>
random neighbors are created. If provided, the input format must be one of:</p><ol><li><p>A list containing:</p><ul><li><p><code>idx</code> an <code>n</code> by <code>k</code> matrix containing the nearest neighbor indices.</p></li>
<li><p><code>dist</code> (optional) an <code>n</code> by <code>k</code> matrix containing the nearest neighbor
distances.</p></li>
</ul><p>If <code>k</code> and <code>init</code> are specified as arguments to this function, and the
number of neighbors provided in <code>init</code> is not equal to <code>k</code> then:</p><ul><li><p>if <code>k</code> is smaller, only the <code>k</code> closest values in <code>init</code> are retained.</p></li>
<li><p>if <code>k</code> is larger, then random neighbors will be chosen to fill <code>init</code> to
the size of <code>k</code>. Note that there is no checking if any of the random
neighbors are duplicates of what is already in <code>init</code> so effectively fewer
than <code>k</code> neighbors may be chosen for some observations under these
circumstances.</p></li>
</ul><p>If the input distances are omitted, they will be calculated for you.</p></li>
<li><p>A random projection forest, such as that returned from <code><a href="rpf_build.html">rpf_build()</a></code> or
<code><a href="rpf_knn.html">rpf_knn()</a></code> with <code>ret_forest = TRUE</code>.</p></li>
</ol></dd>


<dt>epsilon</dt>
<dd><p>Controls trade-off between accuracy and search cost, by
specifying a distance tolerance on whether to explore the neighbors of
candidate points. The larger the value, the more neighbors will be
searched. A value of 0.1 allows query-candidate distances to be 10% larger
than the current most-distant neighbor of the query point, 0.2 means 20%,
and so on. Suggested values are between 0-0.5, although this value is
highly dependent on the distribution of distances in the dataset (higher
dimensional data should choose a smaller cutoff). Too large a value of
<code>epsilon</code> will result in the query search approaching brute force
comparison. Use this parameter in conjunction with
<code><a href="prepare_search_graph.html">prepare_search_graph()</a></code> to prevent excessive run time. Default is 0.1.</p></dd>


<dt>use_alt_metric</dt>
<dd><p>If <code>TRUE</code>, use faster metrics that maintain the
ordering of distances internally (e.g. squared Euclidean distances if using
<code>metric = "euclidean"</code>), then apply a correction at the end. Probably the
only reason to set this to <code>FALSE</code> is if you suspect that some sort of
numeric issue is occurring with your data in the alternative code path. If
a search forest is used for initialization via the <code>init</code> parameter, then
the metric is fetched from there and this setting is ignored.</p></dd>


<dt>n_threads</dt>
<dd><p>Number of threads to use.</p></dd>


<dt>verbose</dt>
<dd><p>If <code>TRUE</code>, log information to the console.</p></dd>


<dt>obs</dt>
<dd><p>set to <code>"C"</code> to indicate that the input <code>query</code> and <code>reference</code>
orientation stores each observation as a column (the orientation must be
consistent). The default <code>"R"</code> means that observations are stored in each
row. Storing the data by row is usually more convenient, but internally
your data will be converted to column storage. Passing it already
column-oriented will save some memory and (a small amount of) CPU usage.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>the approximate nearest neighbor graph as a list containing:</p><ul><li><p><code>idx</code> a <code>n</code> by <code>k</code> matrix containing the nearest neighbor indices
specifying the row of the neighbor in <code>reference</code>.</p></li>
<li><p><code>dist</code> a <code>n</code> by <code>k</code> matrix containing the nearest neighbor distances.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Hajebi, K., Abbasi-Yadkori, Y., Shahbazi, H., &amp; Zhang, H. (2011, June).
Fast approximate nearest-neighbor search with k-nearest neighbor graph.
In <em>Twenty-Second International Joint Conference on Artificial Intelligence</em>.</p>
<p>Harwood, B., &amp; Drummond, T. (2016).
Fanng: Fast approximate nearest neighbour graphs.
In <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>
(pp. 5713-5722).</p>
<p>Iwasaki, M., &amp; Miyazaki, D. (2018).
Optimization of indexing based on k-nearest neighbor graph for proximity
search in high-dimensional data.
<em>arXiv preprint arXiv:1810.07355</em>.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># 100 reference iris items</span></span></span>
<span class="r-in"><span><span class="va">iris_ref</span> <span class="op">&lt;-</span> <span class="va">iris</span><span class="op">[</span><span class="va">iris</span><span class="op">$</span><span class="va">Species</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"setosa"</span>, <span class="st">"versicolor"</span><span class="op">)</span>, <span class="op">]</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># 50 query items</span></span></span>
<span class="r-in"><span><span class="va">iris_query</span> <span class="op">&lt;-</span> <span class="va">iris</span><span class="op">[</span><span class="va">iris</span><span class="op">$</span><span class="va">Species</span> <span class="op">==</span> <span class="st">"versicolor"</span>, <span class="op">]</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># First, find the approximate 4-nearest neighbor graph for the references:</span></span></span>
<span class="r-in"><span><span class="va">iris_ref_graph</span> <span class="op">&lt;-</span> <span class="fu"><a href="nnd_knn.html">nnd_knn</a></span><span class="op">(</span><span class="va">iris_ref</span>, k <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># For each item in iris_query find the 4 nearest neighbors in iris_ref.</span></span></span>
<span class="r-in"><span><span class="co"># You need to pass both the reference data and the reference graph.</span></span></span>
<span class="r-in"><span><span class="co"># If you pass a data frame, non-numeric columns are removed.</span></span></span>
<span class="r-in"><span><span class="co"># set verbose = TRUE to get details on the progress being made</span></span></span>
<span class="r-in"><span><span class="va">iris_query_nn</span> <span class="op">&lt;-</span> <span class="fu">graph_knn_query</span><span class="op">(</span><span class="va">iris_query</span>, <span class="va">iris_ref</span>, <span class="va">iris_ref_graph</span>,</span></span>
<span class="r-in"><span>  k <span class="op">=</span> <span class="fl">4</span>, metric <span class="op">=</span> <span class="st">"euclidean"</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 01:35:46 Using alt metric 'sqeuclidean' for 'euclidean'</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 01:35:46 Initializing from random neighbors</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 01:35:46 Generating random k-nearest neighbor graph from reference with k = 4</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 01:35:46 Searching nearest neighbor graph</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> 01:35:46 Finished</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># A more complete example, converting the initial knn into a search graph</span></span></span>
<span class="r-in"><span><span class="co"># and using a filtered random projection forest to initialize the search</span></span></span>
<span class="r-in"><span><span class="co"># create initial knn and forest</span></span></span>
<span class="r-in"><span><span class="va">iris_ref_graph</span> <span class="op">&lt;-</span> <span class="fu"><a href="nnd_knn.html">nnd_knn</a></span><span class="op">(</span><span class="va">iris_ref</span>, k <span class="op">=</span> <span class="fl">4</span>, init <span class="op">=</span> <span class="st">"tree"</span>, ret_forest <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># keep the best tree in the forest</span></span></span>
<span class="r-in"><span><span class="va">forest</span> <span class="op">&lt;-</span> <span class="fu"><a href="rpf_filter.html">rpf_filter</a></span><span class="op">(</span><span class="va">iris_ref_graph</span>, n_trees <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># expand the knn into a search graph</span></span></span>
<span class="r-in"><span><span class="va">iris_ref_search_graph</span> <span class="op">&lt;-</span> <span class="fu"><a href="prepare_search_graph.html">prepare_search_graph</a></span><span class="op">(</span><span class="va">iris_ref</span>, <span class="va">iris_ref_graph</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># run the query with the improved graph and initialization</span></span></span>
<span class="r-in"><span><span class="va">iris_query_nn</span> <span class="op">&lt;-</span> <span class="fu">graph_knn_query</span><span class="op">(</span><span class="va">iris_query</span>, <span class="va">iris_ref</span>, <span class="va">iris_ref_search_graph</span>,</span></span>
<span class="r-in"><span>  init <span class="op">=</span> <span class="va">forest</span>, k <span class="op">=</span> <span class="fl">4</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by James Melville.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

